{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fa198b3-b91c-4b29-940f-f9fccdfa5a9f",
   "metadata": {},
   "source": [
    "# **Web Scraping Solo Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d926aed-2061-4ef6-b602-64dfd6a79640",
   "metadata": {},
   "source": [
    "## 1. Start by performing a GET request on the url above and convert the response into a BeautifulSoup object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a87c133-3980-4a57-87bd-844b54b75c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bdbb80fc-e961-475a-9db8-211520a8892b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://realpython.github.io/fake-jobs/'\n",
    "\n",
    "# # Not always needed\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"MyPythonScript/1.0 (contact@example.com)\"\n",
    "# }\n",
    "\n",
    "response = requests.get(URL) # (URL, headers = headers) if headers needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1531e622-eaf6-403d-b072-dc925c0ee088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "requests.models.Response"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25009b7d-b9de-462f-a6f2-68f7d36467ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4168e031-e2ee-43c7-ab83-8dffa2f8fe7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get('https://realpython.github.io/fake-jobs/') # (, headers = headers) if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "601c8e10-a251-4d72-b296-d25d1ccfe6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BS(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "37f14125-b1d6-47fb-8375-a5050fa9b080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49702428-affb-4046-8115-49cd347c4965",
   "metadata": {},
   "source": [
    "#### Use the .find method to find the tag containing the first job title (\"Senior Python Developer\"). Hint: can you find a tag type and/or a class that could be helpful for extracting this information? Extract the text from this title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bcbc839-e97e-4a5e-8c69-386ed6334b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Senior Python Developer'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect element to find 'Senior Python Developer' is in tag type 'h2' class 'title is-5'. Using 'title' alone will\n",
    "# return the desired result. *** Take note: class_ *** class does not work\n",
    "\n",
    "soup.find('h2', class_ = ['title', 'is-5']).text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d937aebb-1151-401f-a1c3-6032cfc048f4",
   "metadata": {},
   "source": [
    "#### Now, use what you did for the first title, but extract the job title for all jobs on this page. Store the results in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3424bb2c-1034-4a94-a734-b4576fd9a21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jobtitles = soup.findAll('h2', class_ = ['title', 'is-5'])\n",
    "# print(type(jobtitles))\n",
    "# jobtitles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24657be-cb6d-4205-aad8-5cca837bfe27",
   "metadata": {},
   "source": [
    "#### Finally, extract the companies, locations, and posting dates for each job. For example, the first job has a company of \"Payne, Roberts and Davis\", a location of \"Stewartbury, AA\", and a posting date of \"2021-04-08\". Ensure that the text that you extract is clean, meaning no extra spaces or other characters at the beginning or end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2123e6b9-6918-44e8-9496-0b4f39443120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# h3 class_ = ['subtitle'] ; p class_ = ['location'] ; p class_ = ['is-small']\n",
    "\n",
    "soup.findAll('h2').find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5ba3d6bb-7f85-4179-a5a9-31011ba0466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "jobcards = soup.findAll('div', class_='card-content')\n",
    "\n",
    "data = []\n",
    "\n",
    "for card in jobcards:\n",
    "    title = card.find('h2', class_ = ['title']).text\n",
    "    company = card.find('h3', class_ = ['subtitle']).text\n",
    "    location = card.find('p', class_ = ['location']).text\n",
    "    posting_date = card.find('p', class_ = ['is-small']).text\n",
    "\n",
    "    jobinfo = {\n",
    "        'Title': title.strip(), \n",
    "        'Company': company.strip(),\n",
    "        'Location': location.strip(),\n",
    "        'Date Posted': posting_date.strip()\n",
    "    }\n",
    "\n",
    "    data.append(jobinfo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "22de41d3-e9f4-4826-a468-c4e72dab10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobpostinfo = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7862d613-0704-4889-bff3-4d57b78a3374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date Posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Python Developer</td>\n",
       "      <td>Payne, Roberts and Davis</td>\n",
       "      <td>Stewartbury, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Energy engineer</td>\n",
       "      <td>Vasquez-Davidson</td>\n",
       "      <td>Christopherville, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Legal executive</td>\n",
       "      <td>Jackson, Chambers and Levy</td>\n",
       "      <td>Port Ericaburgh, AA</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fitness centre manager</td>\n",
       "      <td>Savage-Bradley</td>\n",
       "      <td>East Seanview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Product manager</td>\n",
       "      <td>Ramirez Inc</td>\n",
       "      <td>North Jamieview, AP</td>\n",
       "      <td>2021-04-08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title                     Company              Location  \\\n",
       "0  Senior Python Developer    Payne, Roberts and Davis       Stewartbury, AA   \n",
       "1          Energy engineer            Vasquez-Davidson  Christopherville, AA   \n",
       "2          Legal executive  Jackson, Chambers and Levy   Port Ericaburgh, AA   \n",
       "3   Fitness centre manager              Savage-Bradley     East Seanview, AP   \n",
       "4          Product manager                 Ramirez Inc   North Jamieview, AP   \n",
       "\n",
       "  Date Posted  \n",
       "0  2021-04-08  \n",
       "1  2021-04-08  \n",
       "2  2021-04-08  \n",
       "3  2021-04-08  \n",
       "4  2021-04-08  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobpostinfo.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f62a9f-dedf-4c3d-8941-7c92ec252fbf",
   "metadata": {},
   "source": [
    "## 2. Next, add a column that contains the url for the \"Apply\" button. Try this in two ways."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc4b34e-9d9f-44b7-9151-6517ac775e5d",
   "metadata": {},
   "source": [
    "####  First, use the BeautifulSoup find_all method to extract the urls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7465c1-caa8-4669-80ee-2b5fd5b4f84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b6d48e5-5821-4a4a-b958-e95097bb0624",
   "metadata": {},
   "source": [
    "#### Next, get those same urls in a different way. Examine the urls and see if you can spot the pattern of how they are constructed. Then, build the url using the elements you have already extracted. Ensure that the urls that you created match those that you extracted using BeautifulSoup. Warning: You will need to do some string cleaning and prep in constructing the urls this way. For example, look carefully at the urls for the \"Software Engineer (Python)\" job and the \"Scientist, research (maths)\" job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2213487d-76f7-46fa-9133-27860af4f11b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
